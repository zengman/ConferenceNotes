TY  - CONF
TI  - A Utility-Driven Multi-Queue Admission Control Solution for Network Slicing
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 55
EP  - 63
AU  - B. Han
AU  - V. Sciancalepore
AU  - D. Feng
AU  - X. Costa-Perez
AU  - H. D. Schotten
PY  - 2019
KW  - Admission control
KW  - Network slicing
KW  - Delays
KW  - Queueing analysis
KW  - Maintenance engineering
KW  - Network function virtualization
KW  - 5G mobile communication
KW  - 5G
KW  - network slicing
KW  - NFV
KW  - cloud service
KW  - resource management
KW  - queuing theory
DO  - 10.1109/INFOCOM.2019.8737517
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - The combination of recent emerging technologies such as network function virtualization (NFV) and network programmability (SDN) gave birth to the Network Slicing revolution. 5G networks consist of multi-tenant infrastructures capable of offering leased network “slices” to new customers (e.g., vertical industries) enabling a new telecom business model: Slice-as-a-Service (SlaaS). In this paper, we aim i) to study the slicing admission control problem by means of a multi-queuing system for heterogeneous tenant requests, ii) to derive its statistical behavior model, and iii) to provide a utility-based admission control optimization. Our results analyze the capability of the proposed SlaaS system to be approximately Markovian and evaluate its performance as compared to legacy solutions.
ER  - 

TY  - CONF
TI  - DeepTMA: Predicting Effective Contention Models for Network Calculus using Graph Neural Networks
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 1009
EP  - 1017
AU  - F. Geyer
AU  - S. Bondorf
PY  - 2019
KW  - Servers
KW  - Computational modeling
KW  - Delays
KW  - Calculus
KW  - Analytical models
KW  - Predictive models
KW  - Aggregates
DO  - 10.1109/INFOCOM.2019.8737496
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Network calculus computes end-to-end delay bounds for individual data flows in networks of aggregate schedulers. It searches for the best model bounding resource contention between these flows at each scheduler. Analyzing networks, this leads to complex dependency structures and finding the tightest delay bounds becomes a resource intensive task. The exhaustive search for the best combination of contention models is known as Tandem Matching Analysis (TMA). The challenge TMA overcomes is that a contention model in one location of the network can have huge impact on one in another location. These locations can, however, be many analysis steps apart from each other. TMA can derive delay bounds with high degree of tightness but needs several hours of computations to do so. We avoid the effort of exhaustive search altogether by predicting the best contention models for each location in the network. For effective predictions, our main contribution in this paper is a novel framework combining graph-based deep learning and Network Calculus (NC) models. The framework learns from NC, predicts best NC models and feeds them back to NC. Deriving a first heuristic from this framework, called DeepTMA, we achieve provably valid bounds that are very competitive with TMA. We observe a maximum relative error below 6%, while execution times remain nearly constant and outperform TMA in moderately sized networks by several orders of magnitude.
ER  - 

TY  - CONF
TI  - Data-Intensive Routing in Delay-Tolerant Networks
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 2440
EP  - 2448
AU  - K. Sakai
AU  - M. Sun
AU  - W. Ku
PY  - 2019
KW  - Routing
KW  - Routing protocols
KW  - Relays
KW  - Measurement
KW  - Wireless communication
KW  - Buffer storage
KW  - Delay tolerant networks
KW  - DTNs
KW  - routing
KW  - data-intensive protocols
DO  - 10.1109/INFOCOM.2019.8737620
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Mobile users and wireless devices are now the sources of a large volume of data. In such data-intensive mobile and wireless computing systems, delay-tolerant network (DTN) routing plays a critical role in data routing, dissemination, and collection. In this paper, we first introduce a new routing problem in DTNs - data-intensive routing - where data transmitted from one node to another is very large with respect to the size of data which can be transmitted in a single contact and available buffer size at relay nodes. In the proposed opportunistic path model, the contact frequency, contact duration, and buffer constraint are all integrated into a single routing metric. Then, we design the data-intensive routing (DIR) protocol where the path with the highest bottleneck link capacity is defined as the path weight. In addition, we propose the advanced DIR (A-DIR) protocol which focuses on the probability that the last message block will be delivered to its destination within the time constraint. Both the DIR and A-DIR protocols forward messages to better relays or to their destinations based on a greedy strategy with the proposed path metric. Simulations using real mobility traces demonstrate that the proposed DIR and A-DIR protocols achieve their design goals.
ER  - 

TY  - CONF
TI  - Mechanism Design for Network Utility Maximization with Private Constraint Information
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 919
EP  - 927
AU  - M. Zhang
AU  - J. Huang
PY  - 2019
KW  - Resource management
KW  - Distributed algorithms
KW  - Optimization
KW  - Economics
KW  - Throughput
KW  - Nash equilibrium
KW  - Bandwidth
DO  - 10.1109/INFOCOM.2019.8737448
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Network utility maximization (NUM) is a general framework for optimally allocating constrained resources in many networked applications. When agents have asymmetric and private information, a fundamental economic challenge is how to solve the NUM Problem considering the self-interests of strategic agents. Many previous related works have proposed economic mechanisms that can cope with agents’ private utilities. However, the related literature largely neglected the issue of information asymmetries regarding constraints, and limited closely related studies provided solutions only applicable to specific application scenarios. To tackle this issue, we propose the DeNUM Mechanism, the first mechanism for solving a general class of decomposable NUM Problems considering both private utility and constraint information. The key idea is to decentralize the decision process to agents, who will make resource allocation decisions without the need of revealing private information to others. We further show that the DeNUM mechanism yields the network-utility maximizing solution at an equilibrium, and achieves other desirable economic properties (such as individual rationality and budget balance). However, the corresponding equilibrium solution concept, the generalized Nash equilibrium (GNE), makes it difficult to achieve through a distributed algorithm. To address this issue, we further establish the connection between the structure of GNE and that of the primal-dual solution to a reformulated NUM problem, based on which we present the convergent DeNUM Algorithm that is provably convergent. Finally, as a case study, we apply the DeNUM Mechanism to solving the NUM problem for a user-provided network, and show that the DeNUM algorithm improves the network utility by 17% compared to a non-cooperation benchmark.
ER  - 

TY  - CONF
TI  - CG4SR: Near Optimal Traffic Engineering for Segment Routing with Column Generation
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 1333
EP  - 1341
AU  - M. Jadin
AU  - F. Aubry
AU  - P. Schaus
AU  - O. Bonaventure
PY  - 2019
KW  - Routing
KW  - Pricing
KW  - Network topology
KW  - Topology
KW  - Multiprotocol label switching
KW  - Scalability
KW  - Internet
DO  - 10.1109/INFOCOM.2019.8737424
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Segment Routing (SR) is a powerful tool to solve traffic engineering in large networks. It enables steering the traffic along any arbitrary network path while limiting scalability issues as routers do not need to maintain a global state. Mathematical programming approaches proposed so far for SR either do not scale well with the size of topology or impose a strong limit on the number of possible detours (typically at most one). Moreover they do not support Segment Routing fully by ignoring the adjacency segments. This paper leverages column generation, a widely used technique for solving large scale linear programs, combined with a novel dynamic program for solving the pricing problem. Our approach reaches near optimal solutions with gap guarantees by also computing a strong lower-bound tighter than the multi-commodity flow relaxation. It scales even on large topologies and exploits the full expressiveness of SR including adjacency segments. Our experiments compared with existing traffic engineering techniques on various topologies and demand matrices demonstrate the advantages of our approach in terms of scalability, any-time behavior and quality of the solutions.
ER  - 

TY  - CONF
TI  - Joint Placement and Allocation of Virtual Network Functions with Budget and Capacity Constraints
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 523
EP  - 531
AU  - G. Sallam
AU  - B. Ji
PY  - 2019
KW  - Resource management
KW  - Network function virtualization
KW  - Hardware
KW  - Linear programming
KW  - Approximation algorithms
KW  - Relaxation methods
KW  - Web and internet services
DO  - 10.1109/INFOCOM.2019.8737400
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - With the advent of Network Function Virtualization (NFV), network services that traditionally run on proprietary dedicated hardware can now be realized using Virtual Network Functions (VNFs) that are hosted on general-purpose commodity hardware. This new network paradigm offers a great flexibility to Internet service providers (ISPs) for efficiently operating their networks (collecting network statistics, enforcing management policies, etc However, introducing NFV requires an investment to deploy VNFs at certain network nodes (called VNF-nodes), which has to account for practical constraints such as the deployment budget and the VNF-node capacity. To that end, it is important to design a joint VNF-nodes placement and capacity allocation algorithm that can maximize the total amount of network flows that are fully processed by the VNF-nodes while respecting such practical constraints. In contrast to most prior work that often neglects either the budget constraint or the capacity constraint, we explicitly consider both of them. We prove that accounting for these constraints introduces several new challenges. Specifically, we prove that the studied problem is not only NP-hard but also non-submodular. To address these challenges, we introduce a novel relaxation method such that the objective function of the relaxed placement subproblem becomes submodular. Leveraging this useful submodular property, we propose two algorithms that achieve an approximation ratio of $\displaystyle \frac{1}{2} (1\ -\ 1/e)$ and $\displaystyle \frac{1}{3}(1\ -\ 1/e)$ for the original non-relaxed problem, respectively. Finally, we corroborate the effectiveness of the proposed algorithms through extensive evaluations using both trace-driven simulations and simulations based on synthesized network settings.
ER  - 

TY  - CONF
TI  - Hysteresis-based Active Queue Management for TCP Traffic in Data Centers
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 1621
EP  - 1629
AU  - A. M. Abdelmoniem
AU  - B. Bensaou
PY  - 2019
KW  - Data centers
KW  - Control systems
KW  - Bandwidth
KW  - Throughput
KW  - Internet
KW  - Delays
KW  - Virtual machine monitors
KW  - Congestion Control
KW  - Hysteresis
KW  - AQM
KW  - TCP
DO  - 10.1109/INFOCOM.2019.8737369
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Much of the incremental improvement to TCP over the past three decades had the ultimate goal of making it more effective in using the long-fat pipes of the global Internet. This resulted in a rigid set of mechanisms in the protocol that put TCP at a disadvantage in small-delay environments such as data centers. In particular, in the presence of the shallow buffers of commodity switches and the short round trip times in data centers, the continued use of a large TCP initial congestion window and a huge minimum retransmission timeout (both inherited from the Internet-centric design) results in a very short TCP loss cycle that affects particularly the flow completion times of short-lived incast flows. In this paper, we first investigate empirically the TCP loss cycle and discuss its impact on packet losses, recovery and delay; then we propose a switch-based congestion controller with hysteresis (HSCC) that aims to stretch the TCP loss cycle without modifying TCP itself. To protect incast flows from severe congestion, HSCC is designed to transparently induce the TCP source to alternate between its native TCP congestion control algorithm and a slower more conservative constant bit rate flow control mode that is activated when congestion is imminent. We show the stability of HSCC via analytical modelling, and demonstrate its effectiveness via simulation and implementation in a small testbed.
ER  - 

TY  - CONF
TI  - Adaptive Path Tracing with Programmable Bloom Filters in Software-Defined Networks
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 496
EP  - 504
AU  - S. Xiong
AU  - Q. Cao
AU  - W. Si
PY  - 2019
KW  - Network topology
KW  - Lenses
KW  - Debugging
KW  - Data centers
KW  - Routing
KW  - Switches
DO  - 10.1109/INFOCOM.2019.8737387
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - One critical challenge of managing modern data center networks lies in that existing network protocols provide limited visibility on the internal routing and forwarding decisions made by the control plane, leading to difficulties on fast diagnosis and identification of root causes for performance bugs and anomalies. In this paper, we develop and evaluate a “debugging mode” for packet forwarding, where we demonstrate a possible design space by introducing a programmable header field into data packets used for diagnosis purposes. These headers can be manipulated by routers in intermediate hops to perform tracing and diagnosis operations, thereby providing much greater visibility on the control plane and data plane operations. To make this design scalable and feasible, we exploit the software APIs provided by the latest software-defined networking (SDN) technologies, where the network control plane is separated from the underlying data plane, so that we can reprogram the network forwarding functions dynamically. Compared to existing alternative approaches, our approach is adaptive and programmable, allowing dynamic and on-demand receiver-side decoding with extremely low overhead. We emphasize that as this “debugging mode” can be enabled and disabled by network managers as demanded, it introduces zero overhead to normal traffic if everything is operating as expected. Our evaluation results on a real SDN network testbed demonstrate the effectiveness of the proposed approaches.
ER  - 

TY  - CONF
TI  - On the Power of Preprocessing in Decentralized Network Optimization
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 1450
EP  - 1458
AU  - K. Foerster
AU  - J. Hirvonen
AU  - S. Schmid
AU  - J. Suomela
PY  - 2019
KW  - Computational modeling
KW  - Optimization
KW  - Network topology
KW  - Approximation algorithms
KW  - Topology
KW  - Communication networks
KW  - Scalability
KW  - Decentralization
KW  - Local algorithms
KW  - Software-defined networks
DO  - 10.1109/INFOCOM.2019.8737382
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - As communication networks are growing at a fast pace, the need for more scalable approaches to operate such networks is pressing. Decentralization and locality are key concepts to provide scalability. Existing models for which local algorithms are designed fail to model an important aspect of many modern communication networks such as software-defined networks: the possibility to precompute distributed network state. We take this as an opportunity to study the fundamental question of how and to what extent local algorithms can benefit from preprocessing. In particular, we show that preprocessing allows for significant speedups of various networking problems. A main benefit is the precomputation of structural primitives, where purely distributed algorithms have to start from scratch. Maybe surprisingly, we also show that there are strict limitations on how much preprocessing can help in different scenarios. To this end, we provide approximation bounds for the maximum independent set problem—which however show that our obtained speedups are asymptotically optimal. Even though we show that physical link failures in general hinder the power of preprocessing, we can still facilitate the precomputation of symmetry breaking processes to bypass various runtime barriers. We believe that our model and results are of interest beyond the scope of this paper and apply to other dynamic networks as well.
ER  - 

TY  - CONF
TI  - CASA: Congestion and Stretch Aware Static Fast Rerouting
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 469
EP  - 477
AU  - K. Foerster
AU  - Y. Pignolet
AU  - S. Schmid
AU  - G. Tredan
PY  - 2019
KW  - Routing
KW  - Load modeling
KW  - Resilience
KW  - Robustness
KW  - Tagging
KW  - Resource management
KW  - Computer science
DO  - 10.1109/INFOCOM.2019.8737438
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - To meet the stringent requirements on the maximally tolerable disruptions of traffic under link failures, many communication networks feature some sort of static failover mechanism for fast rerouting. However, configuring such static failover mechanisms to achieve a high degree of robustness is known to be challenging, in particular when packet tagging or dynamic node state cannot be used. This paper initiates the systematic study of such local fast failover mechanisms which not only provide connectivity guarantees, even under multiple link failures, but also account for the quality of the resulting failover routes, with respect to locality (i.e., route length) and congestion. Failover quality has received less attention in the literature so far, yet it is increasingly important to support emerging applications.We first show that there exists an inherent tradeoff in terms of achievable locality and congestion of failover routes. We then present CASA, an algorithm providing a high degree of robustness as well as a provable quality of fast rerouting. CASA combines two crucial static resilient routing techniques: combinatorial designs and arc-disjoint arborescences. We complement our formal analysis with a simulation study, in which we compare our algorithms with the state-of-the-art in different scenarios and show benefits in terms of stretch, load, and resilience.
ER  - 

TY  - CONF
TI  - Dynamic Multicast Traffic Engineering with Efficient Rerouting for Software-Defined Networks
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 793
EP  - 801
AU  - J. Kuo
AU  - S. Chiang
AU  - S. Shen
AU  - D. Yang
AU  - W. Chen
PY  - 2019
KW  - Routing
KW  - Bandwidth
KW  - Unicast
KW  - Approximation algorithms
KW  - Multicast algorithms
KW  - Computer science
KW  - Control systems
DO  - 10.1109/INFOCOM.2019.8737563
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Traffic engineering (TE) and efficient network updating have been considered as separate problems in previous SDN research. Traffic engineering mostly focuses on static traffic and does not consider the rerouting overheads to support dynamic traffic. Efficient network updating assumes the new routing is provided by TE and focuses on minimizing only the rerouting overheads, and therefore, the improved new routing with bandwidth consumption similar to the new routing from TE but much lower rerouting overheads has not been explored. In this paper, we explore Multi-tree Low-overhead Multicast Rerouting (MLMR) to jointly solve both problems for SDN multicast. We prove that MLMR is NP-hard and design a new approximation algorithm, named Multicast Rerouting and Update Scheduling Algorithm (MRUSA). Equipped with the notions of deterioration indicator, motivator, and inhibitor, MRUSA provides incremental tree updating and multi-tree update scheduling to address the trade-off between the bandwidth consumption and rerouting overheads. Frequent rerouting due to tiny changes of multicast users can be effectively avoided, because rerouting time for each group can be correctly identified. Simulations and implementation on real SDNs with YouTube traffic manifest that the total cost can be reduced by at least 35% compared with SPT and ST, and the computation time is small for massive SDN.
ER  - 

TY  - CONF
TI  - ReLeS: A Neural Adaptive Multipath Scheduler based on Deep Reinforcement Learning
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 1648
EP  - 1656
AU  - H. Zhang
AU  - W. Li
AU  - S. Gao
AU  - X. Wang
AU  - B. Ye
PY  - 2019
KW  - Scheduling algorithms
KW  - Training
KW  - Delays
KW  - Reinforcement learning
KW  - Neural networks
KW  - Scheduling
KW  - Quality of service
DO  - 10.1109/INFOCOM.2019.8737649
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - The Multipath TCP (MPTCP) protocol, featured by its ability of capacity aggregation across multiple links and connectivity maintenance against single-path failure, has been attracting increasing attention from the industry and academy. Multipath packet scheduling is a unique and fundamental mechanism for the design and implementation of MPTCP, which is responsible for distributing the traffic over multiple subflows. The existing multipath schedulers are facing the challenges of network heterogeneities, comprehensive QoS goals, and dynamic environments, etc. To address these challenges, we propose ReLeS, a Reinforcement Learning based Scheduler for MPTCP. ReLeS uses modern deep reinforcement learning (DRL) techniques to learn a neural network to generate the control policy for packet scheduling. It adopts a comprehensive reward function that takes diverse QoS characteristics into consideration to optimize packet scheduling. To support real-time scheduling, we propose an asynchronous training algorithm that enables parallel execution of packet scheduling, data collecting, and neural network training. We implement ReLeS in the Linux kernel and evaluate it over both emulated and real network conditions. Extensive experiments show that ReLeS significantly outperforms the state-of-the-art schedulers.
ER  - 

TY  - CONF
TI  - FS-Net: A Flow Sequence Network For Encrypted Traffic Classification
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 1171
EP  - 1179
AU  - C. Liu
AU  - L. He
AU  - G. Xiong
AU  - Z. Cao
AU  - Z. Li
PY  - 2019
KW  - Cryptography
KW  - Logic gates
KW  - Hidden Markov models
KW  - Decoding
KW  - Payloads
KW  - Computer architecture
KW  - Recurrent neural networks
DO  - 10.1109/INFOCOM.2019.8737507
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - With more attention paid to user privacy and communication security, the volume of encrypted traffic rises sharply, which brings a huge challenge to traditional rule-based traffic classification methods. Combining machine learning algorithms and manual-design features has become the mainstream methods to solve this problem. However, these features depend on professional experience heavily, which needs lots of human effort. And these methods divide the encrypted traffic classification problem into piece-wise sub-problems, which could not guarantee the optimal solution. In this paper, we apply the recurrent neural network to the encrypted traffic classification problem and propose the Flow Sequence Network (FS-Net). The FS-Net is an end-to-end classification model that learns representative features from the raw flows, and then classifies them in a unified framework. Moreover, we adopt a multi-layer encoder-decoder structure which can mine the potential sequential characteristics of flows deeply, and import the reconstruction mechanism which can enhance the effectiveness of features. Our comprehensive experiments on the real-world dataset covering 18 applications indicate that FS-Net achieves an excellent performance (99.14% TPR, 0.05% FPR and 0.9906 FTF) and outperforms the state-of-the-art methods. Index Terms–Encrypted Traffic Classification, Recurrent Neural Network, Reconstruction Mechanism
ER  - 

TY  - CONF
TI  - Intelligent Edge-Assisted Crowdcast with Deep Reinforcement Learning for Personalized QoE
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 910
EP  - 918
AU  - F. Wang
AU  - C. Zhang
AU  - F. wang
AU  - J. Liu
AU  - Y. Zhu
AU  - H. Pang
AU  - L. Sun
PY  - 2019
KW  - Quality of experience
KW  - Servers
KW  - Bit rate
KW  - Switches
KW  - Bandwidth
KW  - Delays
KW  - Transcoding
DO  - 10.1109/INFOCOM.2019.8737456
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Recent years have seen booming development and great success in interactive crowdsourced livecast (i.e., crowdcast). Different from traditional livecast services, crowdcast is featured with tremendous video contents at the broadcaster side, highly diverse viewer side content watching environments/preferences as well as viewers’ personalized quality of experience (QoE) demands (e.g., individual preferences for streaming delays, channel switching latencies and bitrates). This imposes unprecedented key challenges on how to flexibly and cost-effectively accommodate the heterogeneous and personalized QoE demands for the mass of viewers.In this paper, we propose DeepCast, an edge-assisted crowdcast framework, which makes intelligent decisions at edges based on the massive amount of real-time information from the network and viewers to accommodate personalized QoE with minimized system cost. Given the excessive computation complexity in this context, we propose a data-driven deep reinforcement learning (DRL) based solution that can automatically learn the best suitable strategies for viewer scheduling and transcoding selection. To our best knowledge, DeepCast is the first edge-assisted framework that applies the advance of DRL to explicitly accommodate personalized QoE optimization for crowdcast services. We collect multiple real-world datasets and evaluate the performance of DeepCast using trace-driven experiments. The results demonstrate the superiority of our DeepCast framework and its DRL-based solution.
ER  - 

TY  - CONF
TI  - GCN-GAN: A Non-linear Temporal Link Prediction Model for Weighted Dynamic Networks
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 388
EP  - 396
AU  - K. Lei
AU  - M. Qin
AU  - B. Bai
AU  - G. Zhang
AU  - M. Yang
PY  - 2019
KW  - Predictive models
KW  - Hidden Markov models
KW  - Task analysis
KW  - Topology
KW  - Network topology
KW  - Generative adversarial networks
KW  - Gallium nitride
KW  - Temporal Link Prediction
KW  - Weighted Dynamic Networks
KW  - Generative Adversarial Networks
KW  - Graph Convolutional Networks
DO  - 10.1109/INFOCOM.2019.8737631
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - In this paper, we generally formulate the dynamics prediction problem of various network systems (e.g., the prediction of mobility, traffic and topology) as the temporal link prediction task. Different from conventional techniques of temporal link prediction that ignore the potential non-linear characteristics and the informative link weights in the dynamic network, we introduce a novel non-linear model GCN-GAN to tackle the challenging temporal link prediction task of weighted dynamic networks. The proposed model leverages the benefits of the graph convolutional network (GCN), long short-term memory (LSTM) as well as the generative adversarial network (GAN). Thus, the dynamics, topology structure and evolutionary patterns of weighted dynamic networks can be fully exploited to improve the temporal link prediction performance. Concretely, we first utilize GCN to explore the local topological characteristics of each single snapshot and then employ LSTM to characterize the evolving features of the dynamic networks. Moreover, GAN is used to enhance the ability of the model to generate the next weighted network snapshot, which can effectively tackle the sparsity and the wide-value-range problem of edge weights in real-life dynamic networks. To verify the model’s effectiveness, we conduct extensive experiments on four datasets of different network systems and application scenarios. The experimental results demonstrate that our model achieves impressive results compared to the state-of-the-art competitors.
ER  - 

TY  - CONF
TI  - The Role of Network Topology for Distributed Machine Learning
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 2350
EP  - 2358
AU  - G. Neglia
AU  - G. Calbi
AU  - D. Towsley
AU  - G. Vardoyan
PY  - 2019
KW  - Computational modeling
KW  - Convergence
KW  - Task analysis
KW  - Throughput
KW  - Synchronization
KW  - Network topology
KW  - Servers
DO  - 10.1109/INFOCOM.2019.8737602
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Many learning problems are formulated as minimization of some loss function on a training set of examples. Distributed gradient methods on a cluster are often used for this purpose. In this paper, we study how the variability of task execution times at cluster nodes affects the system throughput. In particular, a simple but accurate model allows us to quantity how the time to solve the minimization problem depends on the network of information exchanges among the nodes. Interestingly, we show that, even when communication overhead may be neglected, the clique is not necessarily the most effective topology, as commonly assumed in previous works.
ER  - 

TY  - CONF
TI  - Joint Content Distribution and Traffic Engineering of Adaptive Videos in Telco-CDNs
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 1342
EP  - 1350
AU  - K. Diab
AU  - M. Hefeeda
PY  - 2019
KW  - Streaming media
KW  - Servers
KW  - Videos
KW  - Solid modeling
KW  - Multimedia systems
KW  - Transcoding
KW  - Adaptive systems
DO  - 10.1109/INFOCOM.2019.8737635
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Telco-CDNs refer to content distribution networks deployed and managed by Internet Service Providers (ISPs). They are getting popular among major ISPs because they offer new revenue streams and have the potential of providing better performance compared to traditional CDNs. Managing telco-CDNs is, however, a complex problem, because it requires jointly managing the network resources (links and switches) and the caching resources (processing and storage capacities), while supporting the adaptive nature and skewed popularity of multimedia content. To address this problem, we present a new algorithm called CAD (Cooperative Active Distribution), which strives to serve as much as possible of the requested multimedia objects within the ISP while carefully engineering the traffic paths through the network. This is achieved by enabling the cooperation among caches within the ISP not only to serve various representations of multimedia objects, but also to create them on demand using the available processing capacity of caches. We have implemented CAD and evaluated it on top of a network emulator that runs deployment code and processes real traffic. Using an actual ISP topology, our experimental results show that CAD achieves substantial performance improvements compared to the closest work in the literature, e.g., up to 64% reduction in the total inter-domain traffic.
ER  - 

TY  - CONF
TI  - Demand-Aware Network Design with Minimal Congestion and Route Lengths
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 1351
EP  - 1359
AU  - C. Avin
AU  - K. Mondal
AU  - S. Schmid
PY  - 2019
KW  - Routing
KW  - Binary trees
KW  - Data centers
KW  - Approximation algorithms
KW  - Network topology
KW  - Entropy
DO  - 10.1109/INFOCOM.2019.8737431
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Emerging communication technologies allow to reconfigure the physical network topology at runtime, enabling demand-aware networks (DANs): networks whose topology is optimized toward the workload they serve. However, today, only little is known about the fundamental algorithmic problems underlying the design of such demand-aware networks. This paper presents the first bounded-degree, demand-aware network, ct-DAN, which minimizes both congestion and route lengths. The designed network is provably (asymptotically) optimal in each dimension individually: we show that there do not exist any bounded-degree networks providing shorter routes (independently of the load), nor do there exist networks providing lower loads (independently of the route lengths). The main building block of the designed ct-DAN networks are ego-trees: communication sources arrange their communication partners in an optimal tree, individually. While the union of these ego-trees forms the basic structure of cl-DANs, further techniques are presented to ensure bounded degrees (for scalability).
ER  - 

TY  - CONF
TI  - DeepCog: Cognitive Network Management in Sliced 5G Networks with Deep Learning
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 280
EP  - 288
AU  - D. Bega
AU  - M. Gramaglia
AU  - M. Fiore
AU  - A. Banchs
AU  - X. Costa-Perez
PY  - 2019
KW  - Resource management
KW  - Deep learning
KW  - Base stations
KW  - Neural networks
KW  - Maximum likelihood detection
KW  - Nonlinear filters
KW  - 5G mobile communication
DO  - 10.1109/INFOCOM.2019.8737488
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - Network slicing is a new paradigm for future 5G networks where the network infrastructure is divided into slices devoted to different services and customized to their needs. With this paradigm, it is essential to allocate to each slice the needed resources, which requires the ability to forecast their respective demands. To this end, we present DeepCog, a novel data analytics tool for the cognitive management of resources in 5G systems. DeepCog forecasts the capacity needed to accommodate future traffic demands within individual network slices while accounting for the operator’s desired balance between resource overprovisioning (i.e., allocating resources exceeding the demand) and service request violations (i.e., allocating less resources than required). To achieve its objective, DeepCog hinges on a deep learning architecture that is explicitly designed for capacity forecasting. Comparative evaluations with real-world measurement data prove that DeepCog’s tight integration of machine learning into resource orchestration allows for substantial (50% or above) reduction of operating expenses with respect to resource allocation solutions based on state-of-the-art mobile traffic predictors. Moreover, we leverage DeepCog to carry out an extensive first analysis of the trade-off between capacity overdimensioning and unserviced demands in adaptive, sliced networks and in presence of real-world traffic.
ER  - 

TY  - CONF
TI  - Hurts to Be Too Early: Benefits and Drawbacks of Communication in Multi-Agent Learning
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 622
EP  - 630
AU  - P. Naghizadeh
AU  - M. Gorlatova
AU  - A. S. Lan
AU  - M. Chiang
PY  - 2019
KW  - Games
KW  - Reinforcement learning
KW  - Information management
KW  - Collaboration
KW  - Timing
KW  - Multi-agent systems
KW  - Decision making
KW  - Multi-agent reinforcement learning
KW  - information sharing
KW  - cooperative games
DO  - 10.1109/INFOCOM.2019.8737652
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - We study a multi-agent partially observable environment in which autonomous agents aim to coordinate their actions, while also learning the parameters of the unknown environment through repeated interactions. In particular, we focus on the role of communication in a multi-agent reinforcement learning problem. We consider a learning algorithm in which agents make decisions based on their own observations of the environment, as well as the observations of other agents, which are collected through communication between agents. We first identify two potential benefits of this type of information sharing when agents’ observation quality is heterogeneous: (1) it can facilitate coordination among agents, and (2) it can enhance the learning of all participants, including the better informed agents. We show however that these benefits of communication depend in general on its timing, so that delayed information sharing may be preferred in certain scenarios.
ER  - 

TY  - CONF
TI  - A Constant Approximation for Maximum Throughput Multicommodity Routing And Its Application to Delay-Tolerant Network Scheduling
T2  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
SP  - 46
EP  - 54
AU  - M. Liu
AU  - A. W. Richa
AU  - M. Rost
AU  - S. Schmid
PY  - 2019
KW  - Throughput
KW  - Approximation algorithms
KW  - IP networks
KW  - Routing
KW  - Capacity planning
KW  - Prediction algorithms
KW  - Scheduling
DO  - 10.1109/INFOCOM.2019.8737402
JO  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
IS  - 
SN  - 2641-9874
VO  - 
VL  - 
JA  - IEEE INFOCOM 2019 - IEEE Conference on Computer Communications
Y1  - 29 April-2 May 2019
AB  - This paper considers the following fundamental maximum throughput routing problem: given a set of k (splittable) multicommodity flows with equal demands in an n-node network, select and route a subset of flows such that the total number of commodities routed that satisfy their demands (i.e., the all-or-nothing throughput) is maximized. Our main contribution is the first constant (i.e., independent of k and n) throughput-approximation algorithm for this NP-hard problem, with sublin-ear, namely $\tilde{O}(\sqrt{k})$, edge capacity violation ratio. Our algorithm is based on a clever application of randomized rounding. We also present an interesting application of our result in the context of delay-tolerant network scheduling. We complement our theoretical contribution with extensive simulation in two different scenarios, and find that our algorithm performs significantly better than predicted in theory, achieving an edge capacity violation ratio of at most 3.
ER  - 


